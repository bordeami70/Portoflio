---
title: "Portfolio CIS 631"
author: "Michael Bordeaux"
date: "7/26/2023"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
```


this is my final project portfolio for CIS 631, in this document I will demonstrate my knowledge of each course objective:



-Describe probability as a foundation of statistical modeling, including inference and maximum likelihood estimation

# Course Objective:

## Determine and apply the appropriate generalized linear model for a specific data context

### showing the course objective:

for this learning objective activity 6 is demonstrating using the appropriate glm for a specfic data context.
```{r include=FALSE}


url <- "https://www.openintro.org/data/csv/resume.csv"

resume <- read_csv(url)


```
exploratory analysis on received_callback variable:
```{r}
ggplot(resume, aes(x = received_callback)) +
  geom_bar() +
  labs(x = "Received Callback", y = "Count")


```


By looking at the above graph we can see that a majority of these resumes did not receive callbacks.

```{r}

resume$received_callback <- factor(resume$received_callback, labels = c("No", "Yes"))

table_data <- table(resume$received_callback)
total <- sum(table_data)
percent <- prop.table(table_data) * 100

table_df <- data.frame(
  received_callback = levels(resume$received_callback),
  n = table_data,
  percent = percent
)

print(table_df)

```

looking at the table above our probablity of a "Yes" is only 8% with an odds .08/(1-.08) of roughly 8% also.

we can further explore this data by adding race into it:

Calculating the probability of a randomly selected person percieved as black it would be ~6% and the odds of a randomly selected resume of a person percieved as black being
called back is .06/(1-.06) roughly also 6%
```{r}
# The {tidymodels} method for logistic regression requires that the response be a factor variable
resume <- resume %>% 
  mutate(received_callback = as.factor(received_callback))

resume_mod <- logistic_reg() %>%
  set_engine("glm") %>%
  fit(received_callback ~ race, data = resume, family = "binomial")

tidy(resume_mod) %>% 
  knitr::kable(digits = 3)
```

regression equation :

y= -2.675 + .438*X + E

to simplify this and look at the equation for corresponding to resumes/persons perceived as black we'd right it as:
y= -2.675 + E

the logg-odds would be: -2.675

and the odds they would be called back is 
roughly .069 or exp(-2.675)

and the probability is .064 of getting called back

linear, trying to fit some sort of a line for some link function 
explore the data and then say the data means this so thats why I chose this model



# Describing the learning objective "Determine and apply the appropriate generalized linear model for a specific data context":

For this learning objective I am using activity 6 to show the determining and applying the appropriate generalized linear model. For this data set it is appropriate to use logistic regression because we have a binary outcome variable. The variable is received_callback which is either a 1 for yes or 0 for no that indicates if a person who submitted there resume received a callback. For the application of this model you can see I first used exploratory graphs to get an understanding of my data set. I think created a table to further analyze my data before approaching this problem. After the initial analysis and more calculating probability and odds I then fit the logistic regression model using glm and passing the binomial attribute. 



## Course Objective "Conduct model selection for a set of candidate models

I will be showing this course objective through mini project 2 - this project really challenged me to select the right model out of all the glm and for the in class assignment I actually selected and fitted the incorrect model. After reflection from seeing other students presentations I then selected the appropriate model:

```{r}
sales <- read.csv("data/inventory.csv")

View(sales)
```

```{r}
ggplot(sales, aes(x = week, y = sold)) +
  geom_line() +
  labs(x = "Week", y = "Units Sold", title = "Sales Over Time")
```

```{r}
total_sales <- sales %>% 
  group_by(item_no) %>% 
  summarise(total_sold = sum(sold))

ggplot(total_sales, aes(x = item_no, y = total_sold)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Item Number", y = "Total Units Sold", title = "Total Sales per Item")
```
```{r}
ggplot(total_sales, aes(x = reorder(item_no, total_sold), y = total_sold)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Item Number", y = "Total Units Sold", title = "Total Sales per Item (Largest to Smallest)") +
  coord_flip()
```
```{r}
total_sales <- sales %>% 
  group_by(item_no) %>% 
  summarise(total_sold = sum(sold)) %>%
  filter(total_sold >= 10000) %>% 
  arrange(desc(total_sold)) 


ggplot(total_sales, aes(x = reorder(item_no, total_sold), y = total_sold)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Item Number", y = "Total Units Sold", title = "Total Sales per Item (Largest to Smallest)") +
  coord_flip() 
```


```{r}
#unique_items <- unique(sales$item_no)

# Print the unique count of item numbers
#cat("List of unique item numbers:\n")
#print(unique_items)


unique_high_sales <- unique(total_sales$item_no)

print(unique_high_sales)
```

```{r}
item_sales <- total_sales %>%
  group_by(item_no) %>%
  summarise(total_sold = sum(total_sold)) %>%
  filter(total_sold > 10000)

# Merge with original dataset to include week
filtered_sales <- item_sales %>%
  inner_join(sales, by = "item_no")%>%
  select(-total_sold)

# Print the filtered dataset
print(filtered_sales)
```
```{r}
ggplot(filtered_sales, aes(x = week, y = sold)) +
  geom_line() +
  labs(x = "Week", y = "Units Sold", title = "Sales Over Time")
```
```{r}


# Fit the Poisson regression model
poisson_model <- glm(sold ~ week + item_no, data = filtered_sales, family = "poisson")

summary(poisson_model)

```
```{r}
# Create a new dataframe for predictions
new_data <- expand.grid(week = 54:56, item_no = unique(filtered_sales$item_no))

# Make predictions using the fitted model
predicted_sales <- predict(poisson_model, newdata = new_data, type = "response")


summary(predicted_sales)


```


## Course Objective "Communicate the results of statistical models to a general audience 



## Use programming software (i.e., R) to fit and assess statistical models

### Show:

please see above examples of using R to fit and assess models.

### describing the objective "Use programming software (i.e., R) to fit and assess statistical models":

Throughout the class I successfully using many different methods in R to fit and assess statistical models. The class activities and in particular the mini compentitions really help push my widen my knowledge of R. I'm feeling extremely conformable after this course to fit and assess models using R, before this class I would've said the only programming software I'm comfortable doing this was SAS.





## reflection on growth:




## Reflection on participation in community:

I attended every class and participated fully with my peers in each breakout session. I wanted to speak up more online but I didn't feel very comfortable with the class being both in person and online so I didn't speak that often. I feel like some of my best participation was on the group assignments. For the first one I worked very succesfully with my teamates to coordinate and contribute meaningfully in discussions. For the second activity I was the driving force in getting my team to meet and work on the project.

