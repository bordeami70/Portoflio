---
title: "Portfolio CIS 631"
author: "Michael Bordeaux"
date: "7/26/2023"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidymodels)
library(forecast)
```


this is my final project portfolio for CIS 631, in this document I will demonstrate my knowledge of each course objective:



-Describe probability as a foundation of statistical modeling, including inference and maximum likelihood estimation

# Course Objective:

## Determine and apply the appropriate generalized linear model for a specific data context

### showing the course objective:

for this learning objective activity 6 is demonstrating using the appropriate glm for a specfic data context.
```{r include=FALSE}


url <- "https://www.openintro.org/data/csv/resume.csv"

resume <- read_csv(url)


```
exploratory analysis on received_callback variable:
```{r}
ggplot(resume, aes(x = received_callback)) +
  geom_bar() +
  labs(x = "Received Callback", y = "Count")


```


By looking at the above graph we can see that a majority of these resumes did not receive callbacks.

```{r}

resume$received_callback <- factor(resume$received_callback, labels = c("No", "Yes"))

table_data <- table(resume$received_callback)
total <- sum(table_data)
percent <- prop.table(table_data) * 100

table_df <- data.frame(
  received_callback = levels(resume$received_callback),
  n = table_data,
  percent = percent
)

print(table_df)

```

looking at the table above our probablity of a "Yes" is only 8% with an odds .08/(1-.08) of roughly 8% also.

we can further explore this data by adding race into it:

Calculating the probability of a randomly selected person percieved as black it would be ~6% and the odds of a randomly selected resume of a person percieved as black being
called back is .06/(1-.06) roughly also 6%
```{r}
# The {tidymodels} method for logistic regression requires that the response be a factor variable
resume <- resume %>% 
  mutate(received_callback = as.factor(received_callback))

resume_mod <- logistic_reg() %>%
  set_engine("glm") %>%
  fit(received_callback ~ race, data = resume, family = "binomial")

tidy(resume_mod) %>% 
  knitr::kable(digits = 3)
```

regression equation :

y= -2.675 + .438*X + E

to simplify this and look at the equation for corresponding to resumes/persons perceived as black we'd right it as:
y= -2.675 + E

the logg-odds would be: -2.675

and the odds they would be called back is 
roughly .069 or exp(-2.675)

and the probability is .064 of getting called back

linear, trying to fit some sort of a line for some link function 
explore the data and then say the data means this so thats why I chose this model



# Describing the learning objective "Determine and apply the appropriate generalized linear model for a specific data context":

For this learning objective I am using activity 6 to show the determining and applying the appropriate generalized linear model. For this data set it is appropriate to use logistic regression because we have a binary outcome variable. The variable is received_callback which is either a 1 for yes or 0 for no that indicates if a person who submitted there resume received a callback. For the application of this model you can see I first used exploratory graphs to get an understanding of my data set. I think created a table to further analyze my data before approaching this problem. After the initial analysis and more calculating probability and odds I then fit the logistic regression model using glm and passing the binomial attribute. 



## Course Objective "Conduct model selection for a set of candidate models"

I will be showing this course objective through mini project 2 - this project really challenged me to select the right model out of all the glm and for the in class assignment I actually selected and fitted the incorrect model. After reflection from seeing other students presentations I then selected the appropriate model:

```{r}
sales <- read.csv("Data/inventory.csv")

```



Here I am plotting the raw data of sales by week to start to understand the data to make model selection:

```{r}
ggplot(sales, aes(x = week, y = sold)) +
  geom_line() +
  labs(x = "Week", y = "Units Sold", title = "Sales Over Time")
```


additional plots to understand the data:

```{r}
total_sales <- sales %>% 
  group_by(item_no) %>% 
  summarise(total_sold = sum(sold))

ggplot(total_sales, aes(x = item_no, y = total_sold)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Item Number", y = "Total Units Sold", title = "Total Sales per Item")
```


additional plots:

```{r}
ggplot(total_sales, aes(x = reorder(item_no, total_sold), y = total_sold)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Item Number", y = "Total Units Sold", title = "Total Sales per Item (Largest to Smallest)") +
  coord_flip()
```


Here I filter down the data to help with my model selection:

```{r}
total_sales <- sales %>% 
  group_by(item_no) %>% 
  summarise(total_sold = sum(sold)) %>%
  filter(total_sold >= 10000) %>% 
  arrange(desc(total_sold)) 


ggplot(total_sales, aes(x = reorder(item_no, total_sold), y = total_sold)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Item Number", y = "Total Units Sold", title = "Total Sales per Item (Largest to Smallest)") +
  coord_flip() 
```


Here I'm printing the list of items I want to use in my model

```{r}



unique_high_sales <- unique(total_sales$item_no)

print(unique_high_sales)
```

```{r}
item_sales <- total_sales %>%
  group_by(item_no) %>%
  summarise(total_sold = sum(total_sold)) %>%
  filter(total_sold > 10000)

# Merge with original dataset to include week
filtered_sales <- item_sales %>%
  inner_join(sales, by = "item_no")%>%
  select(-total_sold)

# Print the filtered dataset
print(filtered_sales)
```
```{r}
ggplot(filtered_sales, aes(x = week, y = sold)) +
  geom_line() +
  labs(x = "Week", y = "Units Sold", title = "Sales Over Time")
```


### here was my first model I selected that was incorrect and did not help me reach the results I wanted:

```{r}


# Fit the Poisson regression model
poisson_model <- glm(sold ~ week + item_no, data = filtered_sales, family = "poisson")

summary(poisson_model)

```
```{r}
# Create a new dataframe for predictions
new_data <- expand.grid(week = 54:56, item_no = unique(filtered_sales$item_no))

# Make predictions using the fitted model
predicted_sales <- predict(poisson_model, newdata = new_data, type = "response")


summary(predicted_sales)


```

### after classmate presentations here I selected an ARIMA model to fit which I felt was more appropriate candidate model to help predict.



here I aggregate the data by week and item number on my data set:
```{r}

aggregated_sales <- aggregate(sold ~ week + item_no, data = filtered_sales, sum)

```

here I am creating the time series:
```{r}

sales_ts <- ts(aggregated_sales$sold, frequency = 52) 

tsdisplay(sales_ts)

```



Creating the arima model:

```{r}

arima_model <- Arima(sales_ts, order = c(1, 1, 1))

```


predicting the next two weeks for all items:


```{r}
forecast_result <- forecast(arima_model, h = 2)


print(forecast_result$mean)
```

## Describing course objective Conduct model selection for a set of candidate models":

In the above you can see me trying out two different models and me iterating through to what I believe was the correct model (after some help from the awesome presentations my classmates gave). This demonstrates the course objective because you can see me iterate through the process of selecting the correct model for a given set of data. For this example I ran through a whole entire poisson model and then heard the feedback from you and my classmates which help guide me in selecting the better model from the candidate models. I think this will parallel who I'll approach selecting models professionally, it will be a largely iterative process with help from mentors and peers to land on a better model to help me demonstrate the results I want.


## Course Objective "Communicate the results of statistical models to a general audience 

For this course objective I feel like mini project 1 worked best to illustrate communicate results of statisical models

### showing "Communicating the results":

Here is my work to non miniproject one to create and fit a MLR model:

```{r}

minidata<- read.csv("Miniprojectdata.csv")
```

```{r}
head(minidata)
```
```{r}
colnames(minidata)
```

writing out variable names to help with clarity and communcation later:


BASMID -> unique child identifier 
ALLGRADEX -> current Grade
EDCPUB-> Type of school - public
SCCHOICE-> choice in school attendance
SPUBCHOIX-> district allows school choice 
SCONSIDR-> other schools considered
SCHLHRSWK-> hours attend school each week
EINTNET-> child enrolled in online or cyber classes
MOSTIMPT-> most important reason for online, virtual, or cyber enrollment
INTNUM->number of online courses
SEENJOY-> child enjoyment of school
SEGRADES-> Child's grades
SEABSNT-> Days absent
SEGRADEQ-> Description of coursework
FSSPORTX-> participation in school activities - attend a school event
FSVOL-> participation in school activities - as a volunteer
FSMTNG->participation in school activities - attend a meeting
FSPTMTNGÎ©->	participation in school activities - attend a parent-teacher meeting
FSATCNFN-> participation in school activities - attend a parent-teacher conference
FSFUNDRS->participate in fundraising
FSCOMMTE-> serve on school commitee
FSCOUNSLR-> meet with counsler
FSFREQ-> times participated in school meetings
FSNOTESX->recieve notes or emails 
FSMEMO-> receive newsletters

creating exploratory graphs:



```{r}
ggplot(minidata, aes(x = SEGRADEQ)) +
  geom_histogram(fill = "lightblue", color = "black", bins =6) +
  labs(x = "Grade", y = "Frequency", title = "Histogram of Grade") +
  theme_minimal()+
  scale_x_continuous(breaks = seq(-1, 5, by = 1))

ggplot(minidata, aes(x = SEENJOY)) +
  geom_histogram(fill = "lightgreen", color = "black", bins =6) +
  labs(x = "Grade", y = "Frequency", title = "Histogram of Grade") +
  theme_minimal()+
  scale_x_continuous(breaks = seq(-1, 5, by = 1))
```


fitting my mlr:


```{r}

model <- lm(SEGRADES ~ ALLGRADEX + EDCPUB + SCCHOICE + SCHLHRSWK + EINTNET + INTNUM + SEENJOY + SEABSNT + SEGRADEQ + FSSPORTX + FSVOL + FSMTNG + FSPTMTNG + FSATCNFN + FSFUNDRS + FSCOMMTE + FSCOUNSLR + FSFREQ + FSNOTESX + FSMEMO, data = minidata)

# Print the model summary
summary(model)

```
```{r}
lm_spec <- linear_reg() %>%
set_mode("regression") %>%
set_engine("lm")

lm_spec

mlr_mod <- lm_spec %>% 
fit(SEGRADES ~ ALLGRADEX + EDCPUB + SCCHOICE + SCHLHRSWK + EINTNET + INTNUM + SEENJOY + SEABSNT + SEGRADEQ + FSSPORTX + FSVOL + FSMTNG + FSPTMTNG + FSATCNFN + FSFUNDRS + FSCOMMTE + FSCOUNSLR + FSFREQ + FSNOTESX + FSMEMO, data = minidata)



tidy(mlr_mod)
```

here are some snips from our slides and I'll show how I would have communicated in my presentation:

first when we went to communicate this model we wanted to go through the lens of how we interpreted the question and how we build the model

* we interpreted the question as how to help parents have there kids be successful
* took out variables that we deemed weren't in the parents control
* expressed that grades were the response variable


in this slide below, it's going through a couple of graphs we used to explore the data. These graphs are particularly important because it shows the some of the variables responses we were dealing with and a all of them were done as a survey with response ranging from -1 to 5 for the most part:

```{r} 

knitr::include_graphics("exploration.PNG") 

```

here is the first model we ran that demonstrates our model equation:

```{r}
knitr::include_graphics("updated model.PNG") 
```


here is the model equation which shows the impact the other variables had on SEGRADES. This equation is particulary imporatant because it shows the results of our model and how are variables impact SEGRADES:

```{r}
knitr::include_graphics("model equation.PNG") 
```

here is the final step we did to compare our model to the null model which is done to show how successful our model was. With our model showing all variables as significant this was an effective model for showing what parents could do to effect their students grades.

```{r}
knitr::include_graphics("Comparing to null.PNG") 
```






### describing the objective "Communicate the results of statistical models to a general audience":

I used mini competition 1 because here I think I (and my team) were able to most effectively communicate to a general audience out of any of the course work. With this example above and other activities in class I think it really sharpened my confidence and ability to express models to a general audience. Specifically above I broke down our process of getting to our model and it's results hopefully in an effective manner. Another example I could've used was from mini project 2, which I also have above. In that example I have the quantities that I predict will be sold in the next two weeks and communicate that to the audience. 



## Curse objective "Use programming software (i.e., R) to fit and assess statistical models:

### Show:

please see above examples of using R to fit and assess models.

### describing the objective "Use programming software (i.e., R) to fit and assess statistical models":

Throughout the class I successfully using many different methods in R to fit and assess statistical models. The class activities and in particular the mini compentitions really help push my widen my knowledge of R. I'm feeling extremely conformable after this course to fit and assess models using R, before this class I would've said the only programming software I'm comfortable doing this was SAS.





## reflection on growth:




## Reflection on participation in community:

I attended every class and participated fully with my peers in each breakout session. I wanted to speak up more online but I didn't feel very comfortable with the class being both in person and online so I didn't speak that often. I feel like some of my best participation was on the group assignments. For the first one I worked very succesfully with my teamates to coordinate and contribute meaningfully in discussions. For the second activity I was the driving force in getting my team to meet and work on the project.

